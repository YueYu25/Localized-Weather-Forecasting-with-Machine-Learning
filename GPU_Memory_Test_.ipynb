{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This section mainly tests the peak video memory required to input data of corresponding size under the same batch size for the local weather forecasting model and the global weather forecasting model, and the time required for a forward-backward training."
      ],
      "metadata": {
        "id": "1hfTXEM8UbLN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s_oqeuLHIwn8"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import gc\n",
        "from numba import cuda\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9SWlNqPKKFB",
        "outputId": "325b36d1-9acc-4efa-8af4-c1c1219d922e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Local weather forecasting model with pooling layers\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        if isinstance(kernel_size, int):\n",
        "            padding = kernel_size // 2\n",
        "        else:\n",
        "            padding = (kernel_size[0] // 2, kernel_size[1] // 2) # kernel_size[0] is height, kernel_size[1] is width\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
        "\n",
        "        self.norm1 = nn.GroupNorm(1, out_channels)\n",
        "        self.norm2 = nn.GroupNorm(1, out_channels)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.norm1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.conv2(x)\n",
        "\n",
        "        x = self.norm2(x)\n",
        "        x = self.activation(x)\n",
        "        x = x + skip\n",
        "        return x\n",
        "\n",
        "class ResNetPatch(nn.Module):\n",
        "    def __init__(self, in_channels=2, out_channels=2, hidden_channels=64, kernel_size=(3, 3), patch_size=68, depth=4):\n",
        "        super().__init__()\n",
        "        self.lift = nn.Conv2d(in_channels, hidden_channels, kernel_size=1)\n",
        "\n",
        "        layers = []\n",
        "        for i in range(depth):\n",
        "            layers.append(ResidualBlock(hidden_channels, hidden_channels, kernel_size))\n",
        "            if i < depth - 1:\n",
        "                 layers.append(nn.MaxPool2d(kernel_size=2, stride=2))  # Maxpooling\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "        final_size = patch_size// (2 ** (depth-1))\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear = nn.Linear(hidden_channels * final_size * final_size, out_channels * 4 * 4)\n",
        "\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lift(x)\n",
        "        x = self.layers(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear(x)\n",
        "        x = x.view(x.size(0), self.out_channels, 4, 4)\n",
        "        return x"
      ],
      "metadata": {
        "id": "yB6_47xpK1Lp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNetPatch(kernel_size=(3, 3), depth=4)\n",
        "x = torch.randn(8, 2, 68, 68)\n",
        "y = model(x)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlHDf0WvK67e",
        "outputId": "1248215b-8584-4fea-9c6d-0cd4e9f2a911"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 2, 4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global weather forecasting model\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        if isinstance(kernel_size, int):\n",
        "            padding = kernel_size // 2\n",
        "        else:\n",
        "            padding = (kernel_size[0] // 2, kernel_size[1] // 2) # kernel_size[0] is height, kernel_size[1] is width\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
        "\n",
        "        self.norm1 = nn.GroupNorm(1, out_channels)\n",
        "        self.norm2 = nn.GroupNorm(1, out_channels)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.norm1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.norm2(x)\n",
        "        x = self.activation(x)\n",
        "        x = x + skip\n",
        "        return x\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels=2,\n",
        "        out_channels=2,\n",
        "        hidden_channels=64,\n",
        "        kernel_size=(3, 3),\n",
        "        depth=4\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        if isinstance(kernel_size, int):\n",
        "            pad = kernel_size // 2\n",
        "        else:\n",
        "            pad = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
        "\n",
        "        self.lift = nn.Conv2d(in_channels, hidden_channels, kernel_size=1)\n",
        "\n",
        "        layers = []\n",
        "        for _ in range(depth):\n",
        "            layers.append(ResidualBlock(hidden_channels, hidden_channels, kernel_size))\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "        self.proj = nn.Conv2d(hidden_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lift(x)\n",
        "\n",
        "        for layer in self.layers:\n",
        "          x = layer(x)\n",
        "\n",
        "        x = self.proj(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "aNyoXxSKKfLM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = ResNet().to(device)"
      ],
      "metadata": {
        "id": "gMnqVLDrLZLz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def measure_performance(model, batch_size, input_shape, device='cuda'):\n",
        "    model = model.to(device)\n",
        "    model.train() # Generate random tensors, simulate input\n",
        "    x = torch.randn(batch_size, *input_shape).to(device)\n",
        "\n",
        "    torch.cuda.reset_peak_memory_stats(device) # Reset memory\n",
        "    start = time.time()\n",
        "\n",
        "    # Forward + Backward\n",
        "    output = model(x)\n",
        "    loss = output.sum()\n",
        "    loss.backward()\n",
        "\n",
        "    elapsed = time.time() - start\n",
        "    mem = torch.cuda.max_memory_allocated(device) / 1024**2  # MB\n",
        "\n",
        "    return mem, elapsed\n"
      ],
      "metadata": {
        "id": "F6Ne03EFLdUJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "full_shape = (2, 256, 512)\n",
        "patch_shape = (2, 68, 68)\n",
        "\n",
        "# Full-map model\n",
        "full_mem, full_time = measure_performance(resnet, batch_size, full_shape, device = 'cuda')\n",
        "\n",
        "# Local model\n",
        "patch_mem, patch_time = measure_performance(model, batch_size, patch_shape, device = 'cuda')\n",
        "\n",
        "# Per-pixel cost\n",
        "full_pixels = batch_size * full_shape[1] * full_shape[2]\n",
        "patch_pixels = batch_size * patch_shape[1] * patch_shape[2]\n",
        "\n",
        "print(f\"Full Model:  BS={batch_size}, Mem={full_mem:.2f}MB, Time={full_time:.4f}s, \"\n",
        "      f\"Mem/px={(full_mem/full_pixels):.6f}MB, Time/px={(full_time/full_pixels):.6e}s\")\n",
        "print(f\"Patch Model: BS={batch_size}, Mem={patch_mem:.2f}MB, Time={patch_time:.4f}s, \"\n",
        "      f\"Mem/px={(patch_mem/patch_pixels):.6f}MB, Time/px={(patch_time/patch_pixels):.6e}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpvDg9w1Lfhp",
        "outputId": "19071a39-9d4d-43ba-ed66-5b43cde25e05"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Model:  BS=16, Mem=13089.85MB, Time=1.2967s, Mem/px=0.006242MB, Time/px=6.183335e-07s\n",
            "Patch Model: BS=16, Mem=212.45MB, Time=0.1014s, Mem/px=0.002872MB, Time/px=1.370491e-06s\n"
          ]
        }
      ]
    }
  ]
}